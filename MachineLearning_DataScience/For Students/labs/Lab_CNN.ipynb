{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Convolutional Layers\n",
    "\n",
    "### Nhung Le\n",
    "\n",
    "### Goals:\n",
    "- Understand Convolution layers \n",
    "- Implement them using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is a convolution operation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import common dependencies\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available==True:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Demo\n",
    "\n",
    "https://cs231n.github.io/convolutional-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input: $W_{input}$ x $H_{input}$ x $D_input$\n",
    "- Hyperparameters:\n",
    "    - Number of filters: K\n",
    "    - Spatial extent: F\n",
    "    - Stride: S\n",
    "    - Amount of zero padding: P\n",
    "- Output:\n",
    "    - $W_{output} = (W_{input} - F + 2P)/S + 1$ \n",
    "    - $H_{output}$ = $(H_{input} - F + 2P)/S + 1$\n",
    "    - $D_{output} = K$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question: What would be the desired input shape for the 1D Convolution layer?\n",
    "desired_shape = (3, 10)\n",
    "\n",
    "#Generate a random tensor of the desired shape\n",
    "x_1d = torch.rand(desired_shape).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6734, 0.9776, 0.1631, 0.5302, 0.2112, 0.1146, 0.0308, 0.0728, 0.1011,\n",
       "         0.3073],\n",
       "        [0.5093, 0.3515, 0.9556, 0.9215, 0.4974, 0.4923, 0.4950, 0.5243, 0.1020,\n",
       "         0.8271],\n",
       "        [0.9698, 0.5891, 0.4597, 0.2905, 0.6432, 0.5759, 0.5958, 0.3005, 0.9802,\n",
       "         0.1018]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowing the module and its attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0min_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mout_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstride\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdilation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgroups\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding_mode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Applies a 1D convolution over an input signal composed of several input\n",
       "planes.\n",
       "\n",
       "In the simplest case, the output value of the layer with input size\n",
       ":math:`(N, C_{\\text{in}}, L)` and output :math:`(N, C_{\\text{out}}, L_{\\text{out}})` can be\n",
       "precisely described as:\n",
       "\n",
       ".. math::\n",
       "    \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n",
       "    \\sum_{k = 0}^{C_{in} - 1} \\text{weight}(C_{\\text{out}_j}, k)\n",
       "    \\star \\text{input}(N_i, k)\n",
       "\n",
       "where :math:`\\star` is the valid `cross-correlation`_ operator,\n",
       ":math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
       ":math:`L` is a length of signal sequence.\n",
       "\n",
       "This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
       "\n",
       "* :attr:`stride` controls the stride for the cross-correlation, a single\n",
       "  number or a one-element tuple.\n",
       "\n",
       "* :attr:`padding` controls the amount of implicit zero-paddings on both sides\n",
       "  for :attr:`padding` number of points.\n",
       "\n",
       "* :attr:`dilation` controls the spacing between the kernel points; also\n",
       "  known as the Ã  trous algorithm. It is harder to describe, but this `link`_\n",
       "  has a nice visualization of what :attr:`dilation` does.\n",
       "\n",
       "* :attr:`groups` controls the connections between inputs and outputs.\n",
       "  :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n",
       "  :attr:`groups`. For example,\n",
       "\n",
       "    * At groups=1, all inputs are convolved to all outputs.\n",
       "    * At groups=2, the operation becomes equivalent to having two conv\n",
       "      layers side by side, each seeing half the input channels,\n",
       "      and producing half the output channels, and both subsequently\n",
       "      concatenated.\n",
       "    * At groups= :attr:`in_channels`, each input channel is convolved with\n",
       "      its own set of filters,\n",
       "      of size\n",
       "      :math:`\\left\\lfloor\\frac{out\\_channels}{in\\_channels}\\right\\rfloor`.\n",
       "\n",
       "Note:\n",
       "\n",
       "    Depending of the size of your kernel, several (of the last)\n",
       "    columns of the input might be lost, because it is a valid\n",
       "    `cross-correlation`_, and not a full `cross-correlation`_.\n",
       "    It is up to the user to add proper padding.\n",
       "\n",
       "Note:\n",
       "\n",
       "    When `groups == in_channels` and `out_channels == K * in_channels`,\n",
       "    where `K` is a positive integer, this operation is also termed in\n",
       "    literature as depthwise convolution.\n",
       "\n",
       "    In other words, for an input of size :math:`(N, C_{in}, L_{in})`,\n",
       "    a depthwise convolution with a depthwise multiplier `K`, can be constructed by arguments\n",
       "    :math:`(C_\\text{in}=C_{in}, C_\\text{out}=C_{in} \\times K, ..., \\text{groups}=C_{in})`.\n",
       "\n",
       "Note:\n",
       "    In some circumstances when using the CUDA backend with CuDNN, this operator\n",
       "    may select a nondeterministic algorithm to increase performance. If this is\n",
       "    undesirable, you can try to make the operation deterministic (potentially at\n",
       "    a performance cost) by setting ``torch.backends.cudnn.deterministic =\n",
       "    True``.\n",
       "    Please see the notes on :doc:`/notes/randomness` for background.\n",
       "\n",
       "\n",
       "Args:\n",
       "    in_channels (int): Number of channels in the input image\n",
       "    out_channels (int): Number of channels produced by the convolution\n",
       "    kernel_size (int or tuple): Size of the convolving kernel\n",
       "    stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
       "    padding (int or tuple, optional): Zero-padding added to both sides of\n",
       "        the input. Default: 0\n",
       "    padding_mode (string, optional): ``'zeros'``, ``'reflect'``,\n",
       "        ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n",
       "    dilation (int or tuple, optional): Spacing between kernel\n",
       "        elements. Default: 1\n",
       "    groups (int, optional): Number of blocked connections from input\n",
       "        channels to output channels. Default: 1\n",
       "    bias (bool, optional): If ``True``, adds a learnable bias to the\n",
       "        output. Default: ``True``\n",
       "\n",
       "Shape:\n",
       "    - Input: :math:`(N, C_{in}, L_{in})`\n",
       "    - Output: :math:`(N, C_{out}, L_{out})` where\n",
       "\n",
       "      .. math::\n",
       "          L_{out} = \\left\\lfloor\\frac{L_{in} + 2 \\times \\text{padding} - \\text{dilation}\n",
       "                    \\times (\\text{kernel\\_size} - 1) - 1}{\\text{stride}} + 1\\right\\rfloor\n",
       "\n",
       "Attributes:\n",
       "    weight (Tensor): the learnable weights of the module of shape\n",
       "        :math:`(\\text{out\\_channels},\n",
       "        \\frac{\\text{in\\_channels}}{\\text{groups}}, \\text{kernel\\_size})`.\n",
       "        The values of these weights are sampled from\n",
       "        :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
       "        :math:`k = \\frac{groups}{C_\\text{in} * \\text{kernel\\_size}}`\n",
       "    bias (Tensor):   the learnable bias of the module of shape\n",
       "        (out_channels). If :attr:`bias` is ``True``, then the values of these weights are\n",
       "        sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
       "        :math:`k = \\frac{groups}{C_\\text{in} * \\text{kernel\\_size}}`\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> m = nn.Conv1d(16, 33, 3, stride=2)\n",
       "    >>> input = torch.randn(20, 16, 50)\n",
       "    >>> output = m(input)\n",
       "\n",
       ".. _cross-correlation:\n",
       "    https://en.wikipedia.org/wiki/Cross-correlation\n",
       "\n",
       ".. _link:\n",
       "    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
       "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?nn.Conv1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we create a Convolution layer and see how that works, let's understand what parameters does our 1D convolution layer need and what would be the expected output?\n",
    "\n",
    "### Questions\n",
    "- Input channels?\n",
    "- Output channels?\n",
    "- Kernel/Filter Size?\n",
    "- Stride?\n",
    "- Padding?\n",
    "\n",
    "https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate a 1D Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d_layer = nn.Conv1d(in_channels= 3,  #Input channels\n",
    "                         out_channels= 5, #Output channels\n",
    "                         kernel_size=3, #Kernel/Filter size\n",
    "                         stride= 1, #Stride\n",
    "                         padding= 1, #Padding; In this case it's zero padding\n",
    "                         bias= True\n",
    "                        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Parameters in the Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in our conv1d_layer is: 50\n"
     ]
    }
   ],
   "source": [
    "print('Number of parameters in our conv1d_layer is: {}'.format(get_n_params(conv1d_layer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_1d = conv1d_layer(x_1d.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Shape of the output??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 10])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_1d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question: What would be the desired input shape for the 2D Convolution layer?\n",
    "desired_shape = (3, 20, 10)\n",
    "\n",
    "#Generate a random tensor of the desired shape\n",
    "x_2d = torch.rand(desired_shape).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowing the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0min_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mout_channels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mkernel_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstride\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdilation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgroups\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding_mode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'zeros'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Applies a 2D convolution over an input signal composed of several input\n",
       "planes.\n",
       "\n",
       "In the simplest case, the output value of the layer with input size\n",
       ":math:`(N, C_{\\text{in}}, H, W)` and output :math:`(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})`\n",
       "can be precisely described as:\n",
       "\n",
       ".. math::\n",
       "    \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n",
       "    \\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k)\n",
       "\n",
       "\n",
       "where :math:`\\star` is the valid 2D `cross-correlation`_ operator,\n",
       ":math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
       ":math:`H` is a height of input planes in pixels, and :math:`W` is\n",
       "width in pixels.\n",
       "\n",
       "This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
       "\n",
       "* :attr:`stride` controls the stride for the cross-correlation, a single\n",
       "  number or a tuple.\n",
       "\n",
       "* :attr:`padding` controls the amount of implicit zero-paddings on both\n",
       "  sides for :attr:`padding` number of points for each dimension.\n",
       "\n",
       "* :attr:`dilation` controls the spacing between the kernel points; also\n",
       "  known as the Ã  trous algorithm. It is harder to describe, but this `link`_\n",
       "  has a nice visualization of what :attr:`dilation` does.\n",
       "\n",
       "* :attr:`groups` controls the connections between inputs and outputs.\n",
       "  :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n",
       "  :attr:`groups`. For example,\n",
       "\n",
       "    * At groups=1, all inputs are convolved to all outputs.\n",
       "    * At groups=2, the operation becomes equivalent to having two conv\n",
       "      layers side by side, each seeing half the input channels,\n",
       "      and producing half the output channels, and both subsequently\n",
       "      concatenated.\n",
       "    * At groups= :attr:`in_channels`, each input channel is convolved with\n",
       "      its own set of filters, of size:\n",
       "      :math:`\\left\\lfloor\\frac{out\\_channels}{in\\_channels}\\right\\rfloor`.\n",
       "\n",
       "The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n",
       "\n",
       "    - a single ``int`` -- in which case the same value is used for the height and width dimension\n",
       "    - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n",
       "      and the second `int` for the width dimension\n",
       "\n",
       "Note:\n",
       "\n",
       "     Depending of the size of your kernel, several (of the last)\n",
       "     columns of the input might be lost, because it is a valid `cross-correlation`_,\n",
       "     and not a full `cross-correlation`_.\n",
       "     It is up to the user to add proper padding.\n",
       "\n",
       "Note:\n",
       "\n",
       "    When `groups == in_channels` and `out_channels == K * in_channels`,\n",
       "    where `K` is a positive integer, this operation is also termed in\n",
       "    literature as depthwise convolution.\n",
       "\n",
       "    In other words, for an input of size :math:`(N, C_{in}, H_{in}, W_{in})`,\n",
       "    a depthwise convolution with a depthwise multiplier `K`, can be constructed by arguments\n",
       "    :math:`(in\\_channels=C_{in}, out\\_channels=C_{in} \\times K, ..., groups=C_{in})`.\n",
       "\n",
       "Note:\n",
       "    In some circumstances when using the CUDA backend with CuDNN, this operator\n",
       "    may select a nondeterministic algorithm to increase performance. If this is\n",
       "    undesirable, you can try to make the operation deterministic (potentially at\n",
       "    a performance cost) by setting ``torch.backends.cudnn.deterministic =\n",
       "    True``.\n",
       "    Please see the notes on :doc:`/notes/randomness` for background.\n",
       "\n",
       "\n",
       "Args:\n",
       "    in_channels (int): Number of channels in the input image\n",
       "    out_channels (int): Number of channels produced by the convolution\n",
       "    kernel_size (int or tuple): Size of the convolving kernel\n",
       "    stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
       "    padding (int or tuple, optional): Zero-padding added to both sides of\n",
       "        the input. Default: 0\n",
       "    padding_mode (string, optional): ``'zeros'``, ``'reflect'``,\n",
       "        ``'replicate'`` or ``'circular'``. Default: ``'zeros'``\n",
       "    dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
       "    groups (int, optional): Number of blocked connections from input\n",
       "        channels to output channels. Default: 1\n",
       "    bias (bool, optional): If ``True``, adds a learnable bias to the\n",
       "        output. Default: ``True``\n",
       "\n",
       "Shape:\n",
       "    - Input: :math:`(N, C_{in}, H_{in}, W_{in})`\n",
       "    - Output: :math:`(N, C_{out}, H_{out}, W_{out})` where\n",
       "\n",
       "      .. math::\n",
       "          H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n",
       "                    \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n",
       "\n",
       "      .. math::\n",
       "          W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n",
       "                    \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n",
       "\n",
       "Attributes:\n",
       "    weight (Tensor): the learnable weights of the module of shape\n",
       "        :math:`(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},`\n",
       "        :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})`.\n",
       "        The values of these weights are sampled from\n",
       "        :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
       "        :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
       "    bias (Tensor):   the learnable bias of the module of shape\n",
       "        (out_channels). If :attr:`bias` is ``True``,\n",
       "        then the values of these weights are\n",
       "        sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
       "        :math:`k = \\frac{groups}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
       "\n",
       "Examples:\n",
       "\n",
       "    >>> # With square kernels and equal stride\n",
       "    >>> m = nn.Conv2d(16, 33, 3, stride=2)\n",
       "    >>> # non-square kernels and unequal stride and with padding\n",
       "    >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
       "    >>> # non-square kernels and unequal stride and with padding and dilation\n",
       "    >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
       "    >>> input = torch.randn(20, 16, 50, 100)\n",
       "    >>> output = m(input)\n",
       "\n",
       ".. _cross-correlation:\n",
       "    https://en.wikipedia.org/wiki/Cross-correlation\n",
       "\n",
       ".. _link:\n",
       "    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
       "\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     Conv2d, ConvBn2d\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?nn.Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 20, 10])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate a 2D Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d_layer = nn.Conv2d(in_channels= 3,  #Input channels\n",
    "                         out_channels= 5, #Output channels\n",
    "                         kernel_size=3, #Kernel/Filter size\n",
    "                         stride= 1, #Stride\n",
    "                         padding= 1, #Padding; In this case it's zero padding\n",
    "                         bias= True\n",
    "                        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d_layer_1 = nn.Conv2d(in_channels= 3,  #Input channels\n",
    "                         out_channels= 5, #Output channels\n",
    "                         kernel_size=(6, 2), #Kernel/Filter size\n",
    "                         stride= (1, 1), #Stride\n",
    "                         padding=  (2, 1), #Padding; In this case it's zero padding\n",
    "                         bias= True\n",
    "                        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Parameters in the Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in our conv2d_layer is: 140\n"
     ]
    }
   ],
   "source": [
    "print('Number of parameters in our conv2d_layer is: {}'.format(get_n_params(conv2d_layer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 20, 10])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input:\n",
    "- N (batchsize) = 1\n",
    "- C = 3\n",
    "- H = 20\n",
    "- W = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = conv2d_layer(x_2d.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = conv2d_layer_1(x_2d.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Shape of the output??\n",
    "\n",
    "Ref: https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 20, 10])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d_layer = nn.Conv2d(in_channels= 3,  #Input channels\n",
    "                         out_channels= 5, #Output channels\n",
    "                         kernel_size=3, #Kernel/Filter size\n",
    "                         stride= 1, #Stride\n",
    "                         padding= 1, #Padding; In this case it's zero padding\n",
    "                         bias= True\n",
    "                        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output: (N, C_out, H_out, W_out)\n",
    "- N = 1\n",
    "- C_out = 5\n",
    "- H_out = (H_in + 2 * padding[0] - dilation[0] * (kernelsize[0] - 1) - 1) / stride [0] + 1\n",
    "        = (20 + 2 * 1 - 1 * (3 - 1) - 1) / 1 + 1\n",
    "        = (19 + 1) = 20\n",
    " \n",
    "- W_out = (W_in + 2 * padding[1] - dilation[1] * (kernelsize[1] - 1) - 1) / stride [1] + 1\n",
    "        = (10 + 2 * 1 - 1 * (3-1) - 1) / 1 + 1\n",
    "        = (9 + 1) = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 20, 10])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d_layer_1 = nn.Conv2d(in_channels= 3,  #Input channels\n",
    "                         out_channels= 5, #Output channels\n",
    "                         kernel_size=(6, 2), #Kernel/Filter size\n",
    "                         stride= (1, 1), #Stride\n",
    "                         padding=  (2, 1), #Padding; In this case it's zero padding\n",
    "                         bias= True\n",
    "                        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output: (N, C_out, H_out, W_out)\n",
    "- N = 1\n",
    "- C_out = 5\n",
    "- H_out = (H_in + 2 * padding[0] - dilation[0] * (kernelsize[0] - 1) - 1) / stride [0] + 1\n",
    "        = (20 + 2 * 2 - 1 * (6 - 1) - 1) / 1 + 1\n",
    "        = (20 + 4 - 5 - 1) + 1 = 19\n",
    " \n",
    "- W_out = (W_in + 2 * padding[1] - dilation[1] * (kernelsize[1] - 1) - 1) / stride [1] + 1\n",
    "        = (10 + 2 * 1 - 1 * (2 - 1) - 1) / 1 + 1\n",
    "        = (10 + 2 - 1 - 1)/1 + 1 = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 19, 11])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding a CNN model using Pytorch with MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size  = 28*28   # images are 28x28 pixels\n",
    "output_size = 10      # there are 10 classes\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=64, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show images\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(12):\n",
    "    plt.subplot(2, 6, i + 1)\n",
    "    image, _ = train_loader.dataset.__getitem__(i)\n",
    "    plt.imshow(image.squeeze().numpy())\n",
    "    plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layers (i.e., Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC1Layer(nn.Module):\n",
    "    def __init__(self, input_size, num_hidden, output_size):\n",
    "        super(FC1Layer, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, num_hidden), \n",
    "            nn.ReLU(), \n",
    "#             nn.Linear(num_hidden, num_hidden), \n",
    "#             nn.ReLU(), \n",
    "            nn.Linear(num_hidden, output_size), \n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, n_feature, output_size):\n",
    "        super(CNN, self).__init__()\n",
    "        self.n_feature = n_feature\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_feature, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(n_feature, n_feature, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(n_feature*4*4, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = x.view(-1, self.n_feature*4*4)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "\n",
    "def train(epoch, model, perm=torch.arange(0, 784).long()):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # send to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # permute pixels\n",
    "        data = data.view(-1, 28*28)\n",
    "        data = data[:, perm]\n",
    "        data = data.view(-1, 1, 28, 28)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model, perm=torch.arange(0, 784).long()):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        # send to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # permute pixels\n",
    "        data = data.view(-1, 28*28)\n",
    "        data = data[:, perm]\n",
    "        data = data.view(-1, 1, 28, 28)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss                                                               \n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Fully-connected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 6370\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.368316\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.898406\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.615707\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.499237\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.248423\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.247924\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.277319\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.421706\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.621405\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.265608\n",
      "\n",
      "Test set: Average loss: 0.3569, Accuracy: 8964/10000 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 8 # number of hidden units\n",
    "\n",
    "model_fnn = FC1Layer(input_size, n_hidden, output_size)\n",
    "model_fnn.to(device)\n",
    "optimizer = optim.SGD(model_fnn.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_fnn)))\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    train(epoch, model_fnn)\n",
    "    test(model_fnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW: TÄng epoch vÃ  cáº£i thiá»n model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a CNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 6422\n"
     ]
    }
   ],
   "source": [
    "# Training settings \n",
    "n_features = 6 # number of feature maps\n",
    "\n",
    "model_cnn = CNN(input_size, n_features, output_size)\n",
    "model_cnn.to(device)\n",
    "optimizer = optim.SGD(model_cnn.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_cnn)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.304552\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 1.602720\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.604802\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.489525\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.319236\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.346442\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.256923\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.151040\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.393339\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.113296\n",
      "\n",
      "Test set: Average loss: 0.1677, Accuracy: 9504/10000 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, 1):\n",
    "    train(epoch, model_cnn)\n",
    "    test(model_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected network vs. CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same parameters, CNN out-performs FCC. Why?\n",
    "- Locality of the image\n",
    "- Stationarity in images\n",
    "\n",
    "What happens when we corrupt the image so the locality and stationarity do not hold true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "perm = torch.randperm(784)\n",
    "# Select 784 because 784 - 28 * 28 = image size\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i in range(10):\n",
    "    image, _ = train_loader.dataset.__getitem__(i)\n",
    "    # permute pixels\n",
    "    image_perm = image.view(-1, 28*28).clone()\n",
    "    image_perm = image_perm[:, perm]\n",
    "    image_perm = image_perm.view(-1, 1, 28, 28)\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    plt.imshow(image.squeeze().numpy())\n",
    "    plt.axis('off')\n",
    "    plt.subplot(4, 5, i + 11)\n",
    "    plt.imshow(image_perm.squeeze().numpy())\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 6370\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.321818\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 1.104664\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.622443\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.552082\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.469185\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.395064\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.285167\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.375628\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.325728\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.418720\n",
      "\n",
      "Test set: Average loss: 0.3504, Accuracy: 9023/10000 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 8    # number of hidden units\n",
    "\n",
    "model_fnn = FC1Layer(input_size, n_hidden, output_size)\n",
    "model_fnn.to(device)\n",
    "optimizer = optim.SGD(model_fnn.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_fnn)))\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    train(epoch, model_fnn, perm)\n",
    "    test(model_fnn, perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 6422\n",
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.340158\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 2.253415\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 2.120775\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 1.606402\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 1.427339\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 1.116175\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.952581\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.702866\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.764009\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.534846\n",
      "\n",
      "Test set: Average loss: 0.6438, Accuracy: 7884/10000 (79%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training settings \n",
    "n_features = 6 # number of feature maps\n",
    "\n",
    "model_cnn = CNN(input_size, n_features, output_size)\n",
    "model_cnn.to(device)\n",
    "optimizer = optim.SGD(model_cnn.parameters(), lr=0.01, momentum=0.5)\n",
    "print('Number of parameters: {}'.format(get_n_params(model_cnn)))\n",
    "\n",
    "for epoch in range(0, 1):\n",
    "    train(epoch, model_cnn, perm)\n",
    "    test(model_cnn, perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
